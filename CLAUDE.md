为了给 Claude 或 Codex 提供清晰的指导，让他们实现一个 **FastLabel** 的 Python+HTML Demo（其中音频是一个应用，主要目标是通过标注来快速训练模型），我们需要一个详细的技术规格文档（spec）。下面是这个 **FastLabel** 项目的完整规范：

---

# **FastLabel Spec: Python+HTML Demo** (用于模型训练与主动学习标注)

## 1. **项目简介**

**目标**：创建一个 Python 后端（Flask）与前端（HTML）结合的 Demo，支持主动学习的标注流程。用户通过网页标注数据，系统基于已标注的数据进行增量训练（每标一轮后训练一次）。本 Demo 针对 **二分类（Binary Classification）** 场景进行了深度优化，支持通过“快速验证”模式实现极速标注。

**主要应用场景**：
* **图像应用**：二分类任务（如：CelebA 人脸属性检测）。
* **核心目标**：**快速标注 + 极速训练 + 闭环反馈**。

## 2. **技术栈**

* **后端**：Python 3 + Flask (默认端口: **8008**)
  * 用于接收前端请求、处理模型训练、执行主动学习策略。
  * 使用 `torch`（支持 MPS/CUDA 设备）处理训练。
  * 使用 `open_clip` (CLIP) 模型进行特征提取。
  * 使用 `scikit-learn` 实现 K-Means 等聚类策略。
* **前端**：HTML5 + CSS3 + Vanilla JS
  * 实现**高密度网格**展示。
  * **点击式切换（Click-to-toggle）**：点击图片即可切换标签（正例/负例），无需下拉框。
  * **沉浸式标注**：背景色随标注模式（验证正例/验证负例）动态变化。
* **存储**：内存（缓存标注数据与模型特征），无需持久化数据库。

## 3. **整体工作流程**

### **标注与训练流程**

1. **选择策略并加载数据**：
   系统根据用户选择的策略（如不确定性或聚类），从待标池中提取一批数据。
2. **沉浸式标注**：
   * 在“验证正例”模式下，系统预测为正的数据被展示，用户只需点掉（标记为负）少数预测错误项。
   * 在“验证负例”模式下同理。
   * 在“混合模式”下，用户手动调整每个项。
3. **增量训练**：
   提交标注后，系统立即在内存中进行增量训练（训练 MLP 分类头，冻结 CLIP 编码器）。
4. **即时反馈**：
   训练完成后，下一批数据的预测置信度将基于最新模型实时更新。

### 主动学习策略

* **Zero-shot Text Init**：输入文本（如 "smiling woman"），系统利用 CLIP 计算文本-图像相似度作为初始分数。结合 "Verify Positives" 策略，可实现无冷启动的快速筛选。
* **Random**：随机采样，用于冷启动（无文本输入时）。
* **K-Means (Diversity)**：通过特征空间聚类，选择各簇中心样本，确保数据多样性。
* **Borderline (Uncertainty)**：选择预测概率接近 0.5 的样本（模型最困惑的边界）。
* **Verify Positives (Easy Positives)**：选择预测概率最高的样本进行快速批量确认（支持 Text Init 结果）。
* **Verify Negatives (Easy Negatives)**：选择预测概率最低的样本进行快速批量确认。

## 4. **后端：功能实现与 API**

### **API 路由**

1. **`/api/set_query`** - 设置初始文本查询：
   * 输入：`{ "query": "text description" }`。
   * 作用：计算 CLIP 文本嵌入，用于在无监督模型时的 Zero-shot 预测。

2. **`/api/next_batch?strategy=STRATEGY&batch_size=N`** - 获取下一批数据：
   * 输入：策略名称及可选的批次大小。
   * 输出：`{ "items": [...], "batch_type": "positive/negative/neutral" }`。
   * **排序优化**：系统会自动按置信度排序返回数据，以辅助快速视觉扫描。每个 item 包含：`id`, `image` (base64), `prob_pos` (置信度)。

2. **`/api/submit_labels`** - 提交标注结果：
   * 输入：`[{"id": 1, "label": 1}, ...]`。
   * 逻辑：更新内存状态 -> 触发 `train_step()`。

## 5. **前端：用户交互**

### **界面规范**

* **视觉反馈**：
  * 正例（Positive）：**绿色边框**。
  * 负例（Negative）：**红色边框** + 半透明（去强调）。
  * 验证模式：页面背景变为浅绿色或浅红色以提醒当前任务。
* **交互逻辑**：
  * **单点切换**：在卡片上任意位置点击，即在该图片的 0/1 标签间循环切换。
  * **批量提交**：点击“Confirm & Train”一次性提交整页标注。

```html
<!-- 卡片结构 -->
<div class="card is-positive">
    <img src="..." />
    <div class="card-overlay">#ID - 98% Pos</div>
</div>
```

## 6. **数据与性能**

* **数据源**：CelebA Sprite (48x48 像素，200x150 网格)。
* **性能优化**：
  * **CLIP 嵌入缓存**：所有图片的特征提取仅在首次访问时进行并缓存。
  * **批量预测**：使用 PyTorch 的张量化操作一次性预测全批次。
  * **高密度 UI**：每屏展示 24+ 张图片，减少滚动和翻页。

## 7. **开发注意事项**

* **端口固定**：必须使用 **8008** 端口，禁止擅自修改。
* **硬件加速**：代码应自动检测并使用 `cuda` 或 `mps` 设备。

---

### 总结
FastLabel 是一个面向实战的主动学习 Demo，核心优势在于通过**极简的交互**（点击切换）和**针对性的策略**（批量验证）将模型迭代的时间从小时级缩短到秒级。